version: '3.8'

# 开发环境配置 - 支持代码热更新
services:
  # Redis 消息总线
  redis:
    image: redis:7-alpine
    container_name: aivtuber-redis-dev
    ports:
      - "6379:6379"
    volumes:
      - redis_dev_data:/data
    restart: "no"
    command: redis-server --appendonly yes

  # 网关服务
  gateway:
    build:
      context: ./services/gateway-python
      dockerfile: Dockerfile
    container_name: aivtuber-gateway-dev
    ports:
      - "8000:8000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - PYTHONPATH=/app
      - FLASK_ENV=development
      - FLASK_DEBUG=1
      # 支持通过 .env 覆盖，未提供时使用默认值
      - INPUT_HANDLER_URL=${INPUT_HANDLER_URL:-ws://input-handler:8001}
      - OUTPUT_HANDLER_URL=${OUTPUT_HANDLER_URL:-ws://output-handler:8002}
    volumes:
      - ./services/gateway-python:/app
    restart: "no"
    depends_on:
      - redis

  # 同步主链路：dialog-engine（M1）
  dialog-engine:
    build:
      context: ./services/dialog-engine
      dockerfile: Dockerfile
    container_name: aivtuber-dialog-engine-dev
    environment:
      - PORT=8100
      - PYTHONPATH=/app/src
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - SYNC_TTS_STREAMING=${SYNC_TTS_STREAMING:-false}
      - SYNC_TTS_BARGE_IN=${SYNC_TTS_BARGE_IN:-false}
      - SYNC_TTS_PROVIDER=${SYNC_TTS_PROVIDER:-mock}
      - OUTPUT_INGEST_WS_URL=${OUTPUT_INGEST_WS_URL:-ws://output-handler:8002/ws/ingest/tts}
      # Mock TTS defaults (can be overridden in .env for STOP testing)
      - MOCK_TTS_CHUNK_DELAY_MS=${MOCK_TTS_CHUNK_DELAY_MS:-200}
      - MOCK_TTS_CHUNK_COUNT=${MOCK_TTS_CHUNK_COUNT:-50}
      # Edge TTS defaults (M4)
      - EDGE_TTS_VOICE=${EDGE_TTS_VOICE:-zh-CN-XiaoxiaoNeural}
      - EDGE_TTS_RATE=${EDGE_TTS_RATE:-+0%}
      - EDGE_TTS_VOLUME=${EDGE_TTS_VOLUME:-+0%}
      - EDGE_TTS_OUTPUT_FORMAT=${EDGE_TTS_OUTPUT_FORMAT:-riff-24khz-16bit-mono-pcm}
      # Async extensions (M3)
      - ENABLE_ASYNC_EXT=${ENABLE_ASYNC_EXT:-false}
      - OUTBOX_FLUSH_INTERVAL_MS=${OUTBOX_FLUSH_INTERVAL_MS:-500}
      - EVENT_STREAM_MAXLEN=${EVENT_STREAM_MAXLEN:-100000}
      # Feature flags & LLM config
      - ENABLE_REAL_LLM=${ENABLE_REAL_LLM:-false}
      - ENABLE_SHORT_TERM_MEMORY=${ENABLE_SHORT_TERM_MEMORY:-true}
      - STM_DB_PATH=${STM_DB_PATH:-/app/data/dialog_memory.sqlite}
      - STM_CONTEXT_TURNS=${STM_CONTEXT_TURNS:-20}
      - ENABLE_LTM_INLINE=${ENABLE_LTM_INLINE:-false}
      - LTM_BASE_URL=${LTM_BASE_URL:-http://memory-python:8200}
      - LTM_RETRIEVE_PATH=${LTM_RETRIEVE_PATH:-/v1/memory/retrieve}
      - LTM_RETRIEVE_TIMEOUT=${LTM_RETRIEVE_TIMEOUT:-3}
      - LTM_MAX_SNIPPETS=${LTM_MAX_SNIPPETS:-5}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-}
      - OPENAI_ORG_ID=${OPENAI_ORG_ID:-}
      - LLM_MODEL=${LLM_MODEL:-gpt-4o-mini}
      - LLM_TEMPERATURE=${LLM_TEMPERATURE:-0.7}
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS:-1024}
      - LLM_TOP_P=${LLM_TOP_P:-1.0}
      - LLM_FREQUENCY_PENALTY=${LLM_FREQUENCY_PENALTY:-0.0}
      - LLM_PRESENCE_PENALTY=${LLM_PRESENCE_PENALTY:-0.0}
      - LLM_REQUEST_TIMEOUT=${LLM_REQUEST_TIMEOUT:-30}
      - LLM_RETRY_LIMIT=${LLM_RETRY_LIMIT:-2}
      - LLM_RETRY_BACKOFF_SECONDS=${LLM_RETRY_BACKOFF_SECONDS:-0.5}
    ports:
      - "8100:8100"
    volumes:
      - ./services/dialog-engine/src:/app/src
      - ./services/dialog-engine/tests:/app/tests
      - dialog_engine_data:/app/data
    restart: "no"
    depends_on:
      - redis

  # ASR语音识别服务
  asr:
    build:
      context: ./services/asr-python
      dockerfile: Dockerfile
    container_name: aivtuber-asr-dev
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - PYTHONPATH=/app
    volumes:
      - ./services/asr-python:/app
      - ./utils:/app/shared_utils
    command: ["python", "dev_runner.py"]
    restart: "no"
    depends_on:
      - redis

  # 输入处理服务
  input-handler:
    build:
      context: ./services/input-handler-python
      dockerfile: Dockerfile
    container_name: aivtuber-input-handler-dev
    environment:
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - PYTHONPATH=/app
      - ENABLE_SYNC_CORE=${ENABLE_SYNC_CORE:-false}
      - DIALOG_ENGINE_URL=${DIALOG_ENGINE_URL:-http://dialog-engine:8100}
    volumes:
      - ./services/input-handler-python:/app
      - temp_files:/tmp/aivtuber_tasks
    restart: "no"
    depends_on:
      - redis

  # 记忆服务
  memory:
    build:
      context: ./services/memory-python
      dockerfile: Dockerfile
    container_name: aivtuber-memory-dev
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - PYTHONPATH=/app
    volumes:
      - ./services/memory-python:/app
      - ./utils:/app/shared_utils
      - memory_dev_data:/app/data
    command: ["python", "dev_runner.py"]
    restart: "no"
    depends_on:
      - redis

  # PostgreSQL数据库 (用于pgvector)
  postgres:
    image: pgvector/pgvector:pg16
    container_name: aivtuber-postgres-dev
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=${POSTGRES_DB:-ltm_vectors}
      - POSTGRES_USER=${POSTGRES_USER:-ltm_user}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-ltm_password}
    volumes:
      - postgres_dev_data:/var/lib/postgresql/data
    restart: "no"

  # 长期记忆服务
  long-term-memory:
    build:
      context: ./services/long-term-memory-python
      dockerfile: Dockerfile
    container_name: aivtuber-long-term-memory-dev
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - PGVECTOR_HOST=postgres
      - PGVECTOR_PORT=5432
      - PGVECTOR_DATABASE=${POSTGRES_DB:-ltm_vectors}
      - PGVECTOR_USER=${POSTGRES_USER:-ltm_user}
      - PGVECTOR_PASSWORD=${POSTGRES_PASSWORD:-ltm_password}
      - MEM0_CONFIG_PATH=config/mem0_config.yaml
      - PYTHONPATH=/app
    volumes:
      - ./services/long-term-memory-python:/app
      - ltm_dev_data:/app/data
      - ltm_dev_logs:/app/logs
    command: ["python", "dev_runner.py"]
    restart: "no"
    depends_on:
      - redis
      - postgres

  # AI聊天服务
  chat-ai:
    build:
      context: ./services/chat-ai-python
      dockerfile: Dockerfile
    container_name: aivtuber-chat-ai-dev
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - PYTHONPATH=/app
      - ENABLE_LTM=${ENABLE_LTM:-true}
      - LTM_REQUESTS_QUEUE=${LTM_REQUESTS_QUEUE:-ltm_requests}
      - LTM_RESPONSES_CHANNEL=${LTM_RESPONSES_CHANNEL:-ltm_responses}
    volumes:
      - ./services/chat-ai-python:/app
      - ./utils:/app/shared_utils
    command: ["python", "dev_runner.py"]
    restart: "no"
    depends_on:
      - redis

  # 输出处理服务
  output-handler:
    build:
      context: ./services/output-handler-python
      dockerfile: Dockerfile
    container_name: aivtuber-output-handler-dev
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - PYTHONPATH=/app
      # Feature flags（可在 .env 覆盖）
      - SYNC_TTS_STREAMING=${SYNC_TTS_STREAMING:-false}
      - SYNC_TTS_BARGE_IN=${SYNC_TTS_BARGE_IN:-false}
    volumes:
      - ./services/output-handler-python:/app
      - temp_files:/tmp/aivtuber_tasks
    restart: "no"
    depends_on:
      - redis

  # Async workers (M3)
  async-workers-ltm:
    build:
      context: ./services/async-workers
      dockerfile: Dockerfile
    container_name: aivtuber-async-ltm-dev
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - PYTHONPATH=/app
      - LTM_STREAM=events.ltm
      - LTM_GROUP=ltm-workers
    command: ["python", "ltm_worker.py"]
    volumes:
      - ./services/async-workers:/app/services/async-workers
    restart: "no"
    depends_on:
      - redis

  async-workers-analytics:
    build:
      context: ./services/async-workers
      dockerfile: Dockerfile
    container_name: aivtuber-async-analytics-dev
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - PYTHONPATH=/app
      - ANALYTICS_STREAM=events.analytics
      - ANALYTICS_GROUP=a11y-workers
    command: ["python", "analytics_worker.py"]
    volumes:
      - ./services/async-workers:/app/services/async-workers
    restart: "no"
    depends_on:
      - redis

  # TTS语音合成服务
  tts:
    build:
      context: ./services/tts-python
      dockerfile: Dockerfile
    container_name: aivtuber-tts-dev
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - PYTHONPATH=/app
    volumes:
      - ./services/tts-python:/app
      - ./utils:/app/shared_utils
      - temp_files:/tmp/aivtuber_tasks
    command: ["python", "dev_runner.py"]
    restart: "no"
    depends_on:
      - redis

volumes:
  redis_dev_data:
  memory_dev_data:
  postgres_dev_data:
  ltm_dev_data:
  ltm_dev_logs:
  temp_files:
  dialog_engine_data:

networks:
  default:
    name: aivtuber-dev-network
