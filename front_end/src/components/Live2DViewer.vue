<template>
  <div class="live2d-container" ref="live2dContainer">
    <canvas 
      ref="live2dCanvas" 
      class="live2d-canvas"
      @mousemove="handlePointerMove"
      @click="handleCanvasClick"
      @touchmove="handlePointerMove"
    ></canvas>
    <div v-if="loading" class="loading-overlay">
      <v-progress-circular indeterminate color="primary" size="50"></v-progress-circular>
      <p class="mt-2">åŠ è½½Live2Dæ¨¡å‹ä¸­...</p>
    </div>
    <div v-if="error" class="error-overlay">
      <v-icon color="error" size="48">mdi-alert-circle</v-icon>
      <p class="mt-2 text-error">{{ error }}</p>
    </div>
  </div>
</template>

<script setup>
import { ref, onMounted, onUnmounted, nextTick, watch, shallowRef } from 'vue'
import Live2DManager from '../live2d/utils/Live2DManager.js'
import { useApi } from '@/composables/useApi.js' // å¼•å…¥ useApi

// Props
const props = defineProps({
  modelPath: {
    type: String,
    default: '/live2d/models/Haru/Haru.model3.json'
  },
  width: {
    type: Number,
    default: 400
  },
  height: {
    type: Number,
    default: 600
  },
  motions: {
    type: Array,
    default: () => []
  },
  expressions: {
    type: Array,
    default: () => []
  }
})

// Emits
const emit = defineEmits(['model-loaded', 'model-error'])

// Reactive data
const live2dContainer = ref(null)
const live2dCanvas = ref(null)
const loading = ref(true)
const error = ref('')

// --- Web Audio API State ---
const audioContext = shallowRef(null)
const analyserNode = shallowRef(null)
const audioSource = shallowRef(null)
const audioBuffer = shallowRef(null)
const isPlayingAudio = ref(false)
const audioContextReady = ref(false) // æ ‡è®°AudioContextæ˜¯å¦å·²å‡†å¤‡å¥½
const userInteracted = ref(false) // æ ‡è®°ç”¨æˆ·æ˜¯å¦å·²äº¤äº’
const isTestingLipSync = ref(false) // æ ‡è®°æ˜¯å¦æ­£åœ¨æµ‹è¯•å£å‹åŒæ­¥
let animationFrameId = null

// --- æµ‹è¯•åŠŸèƒ½ (éœ€è¦åœ¨æ¨¡æ¿ä½¿ç”¨å‰å®šä¹‰) ---

/**
 * æµ‹è¯•å£å‹åŒæ­¥åŠ¨ç”» - æ¨¡æ‹ŸéŸ³é¢‘é©±åŠ¨çš„å£å‹å˜åŒ–
 */
const testLipSyncAnimation = () => {
  if (!live2dManager || !live2dManager.isModelLoaded) {
    console.warn('Live2Dæ¨¡å‹æœªåŠ è½½å®Œæˆ');
    return;
  }
  
  if (isTestingLipSync.value) {
    console.warn('å£å‹åŒæ­¥æµ‹è¯•å·²åœ¨è¿›è¡Œä¸­');
    return;
  }
  
  // æ ‡è®°ç”¨æˆ·å·²äº¤äº’
  if (!userInteracted.value) {
    userInteracted.value = true;
    console.log('User interaction detected during lip sync test.');
  }
  
  isTestingLipSync.value = true;
  console.log('ğŸ­ å¼€å§‹æµ‹è¯•å£å‹åŒæ­¥åŠ¨ç”»...');
  
  const startTime = Date.now();
  const duration = 5000; // 5ç§’æµ‹è¯•æ—¶é•¿
  
  const animateLipSync = () => {
    const elapsed = Date.now() - startTime;
    const progress = elapsed / duration;
    
    if (progress >= 1.0) {
      // æµ‹è¯•ç»“æŸï¼Œé‡ç½®å£å‹
      if (live2dManager) {
        live2dManager.setLipSyncValue(0.0);
      }
      isTestingLipSync.value = false;
      console.log('âœ… å£å‹åŒæ­¥æµ‹è¯•å®Œæˆ');
      return;
    }
    
    // ç”Ÿæˆæ¨¡æ‹Ÿçš„éŸ³é¢‘æ³¢å½¢ - å¤šç§æ³¢å½¢çš„ç»„åˆ
    const time = elapsed / 1000;
    const wave1 = Math.sin(time * 2) * 0.3; // ä½é¢‘æ³¢
    const wave2 = Math.sin(time * 8) * 0.4; // ä¸­é¢‘æ³¢  
    const wave3 = Math.sin(time * 15) * 0.2; // é«˜é¢‘æ³¢
    const noise = (Math.random() - 0.5) * 0.1; // éšæœºå™ªå£°
    
    // ç»„åˆæ³¢å½¢å¹¶å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
    let lipValue = (wave1 + wave2 + wave3 + noise + 1) / 2;
    lipValue = Math.max(0, Math.min(1, lipValue));
    
    // æ·»åŠ ä¸€äº›"è¯´è¯"çš„èŠ‚å¥æ„Ÿ
    const speechPattern = Math.sin(time * 3) * 0.5 + 0.5;
    lipValue *= speechPattern;
    
    // è®¾ç½®å£å‹å€¼
    if (live2dManager) {
      live2dManager.setLipSyncValue(lipValue);
    }
    
    // ç»§ç»­åŠ¨ç”»
    requestAnimationFrame(animateLipSync);
  };
  
  // å¼€å§‹åŠ¨ç”»
  animateLipSync();
};

/**
 * æµ‹è¯•éšæœºåŠ¨ä½œ
 */
const testRandomMotion = () => {
  if (!live2dManager || !live2dManager.isModelLoaded) {
    console.warn('Live2Dæ¨¡å‹æœªåŠ è½½å®Œæˆ');
    return;
  }
  
  // æ ‡è®°ç”¨æˆ·å·²äº¤äº’
  if (!userInteracted.value) {
    userInteracted.value = true;
    console.log('User interaction detected during motion test.');
  }
  
  // æ’­æ”¾éšæœºåŠ¨ä½œ
  live2dManager.playRandomMotion('Idle', 3);
  console.log('ğŸª æ’­æ”¾éšæœºåŠ¨ä½œ');
};

// --- Composables ---
const { processingError } = useApi()

// Live2D Manager instance
let live2dManager = null

// Initialize Live2D
const initLive2D = async () => {
  try {
    loading.value = true
    error.value = ''
    
    // Wait for next tick to ensure DOM is ready
    await nextTick()
    
    if (!live2dCanvas.value) {
      throw new Error('Canvas element not found')
    }
    
    // Set canvas size with high DPI support - ä½¿ç”¨å®¹å™¨çš„å®é™…å°ºå¯¸
    const devicePixelRatio = window.devicePixelRatio || 1
    const containerRect = live2dContainer.value.getBoundingClientRect()
    const displayWidth = containerRect.width || props.width
    const displayHeight = containerRect.height || props.height
    
    // Set actual canvas size (high resolution)
    live2dCanvas.value.width = displayWidth * devicePixelRatio
    live2dCanvas.value.height = displayHeight * devicePixelRatio
    
    // Set display size (CSS pixels) - è®©canvaså æ»¡æ•´ä¸ªå®¹å™¨
    live2dCanvas.value.style.width = '100%'
    live2dCanvas.value.style.height = '100%'
    
    // Create Live2D Manager
    live2dManager = new Live2DManager()
    
    // Initialize framework
    await live2dManager.initialize(live2dCanvas.value)
    
    // Load model
    const model = await live2dManager.loadModel(props.modelPath)
    
    // Start rendering
    live2dManager.startRendering()
    
    loading.value = false
    
    // è·å–æ¨¡å‹çš„HitAreasä¿¡æ¯
    updateModelHitAreas()
    
    emit('model-loaded', model)
    console.log('Live2D model loaded successfully')
    
  } catch (err) {
    console.error('Failed to initialize Live2D:', err)
    error.value = `åˆå§‹åŒ–å¤±è´¥: ${err.message}`
    loading.value = false
    emit('model-error', err)
  }
}

// Handle mouse/touch events
const handlePointerMove = (event) => {
  if (!live2dManager || !live2dCanvas.value) return
  
  // æ ‡è®°ç”¨æˆ·å·²äº¤äº’
  if (!userInteracted.value) {
    userInteracted.value = true
    console.log('User interaction detected, audio features enabled.')
  }
  
  const rect = live2dCanvas.value.getBoundingClientRect()
  const x = event.clientX - rect.left
  const y = event.clientY - rect.top
  
  live2dManager.onPointerMove(x, y)
}

// Handle canvas click for interactions
const handleCanvasClick = (event) => {
  if (!live2dManager) return
  
  // æ ‡è®°ç”¨æˆ·å·²äº¤äº’å¹¶å°è¯•åˆå§‹åŒ–AudioContext
  if (!userInteracted.value) {
    userInteracted.value = true
    console.log('User interaction detected, attempting to initialize AudioContext.')
    initAudioContext()
  }
  
  console.log('=== ç‚¹å‡»äº‹ä»¶è°ƒè¯•ä¿¡æ¯ ===')
  console.log('props.motions:', props.motions)
  console.log('motionsæ•°é‡:', props.motions.length)
  
  const rect = live2dCanvas.value.getBoundingClientRect()
  const x = event.clientX - rect.left
  const y = event.clientY - rect.top
  
  // å°†ç‚¹å‡»åæ ‡è½¬æ¢ä¸ºç›¸å¯¹äºcanvasçš„æ¯”ä¾‹åæ ‡
  const relativeX = x / rect.width
  const relativeY = y / rect.height
  
  // æ£€æŸ¥æ˜¯å¦ç‚¹å‡»äº†å…³è”çš„åŒºåŸŸ
  const clickedResult = findMotionByClickArea(relativeX, relativeY)
  
  if (clickedResult) {
    if (clickedResult.type === 'expression') {
      // è¡¨æƒ…å·²åœ¨findMotionByClickAreaä¸­æ‰§è¡Œ
      console.log(`ç‚¹å‡»è§¦å‘è¡¨æƒ…: ${clickedResult.item.name}`)
    } else if (clickedResult.type === 'motion') {
      // åŠ¨ä½œå·²åœ¨findMotionByClickAreaä¸­æ‰§è¡Œ
      console.log(`ç‚¹å‡»è§¦å‘åŠ¨ä½œ: ${clickedResult.item.name}`)
    }
  } else {
    // é»˜è®¤è¡Œä¸ºï¼šæ’­æ”¾éšæœºåŠ¨ä½œ
    console.log('æœªåŒ¹é…åˆ°å…³è”åŠ¨ä½œæˆ–è¡¨æƒ…ï¼Œæ’­æ”¾éšæœºåŠ¨ä½œ')
    randomMotion()
  }
  console.log('=== ç‚¹å‡»äº‹ä»¶è°ƒè¯•ç»“æŸ ===')
}

// æ ¹æ®ç‚¹å‡»åæ ‡æŸ¥æ‰¾å…³è”çš„åŠ¨ä½œ
const findMotionByClickArea = (x, y) => {
  if (!live2dManager || !live2dManager.isModelLoaded) {
    return null
  }
  
  // è·å–canvasçš„æ˜¾ç¤ºå°ºå¯¸
  const canvas = live2dCanvas.value
  if (!canvas) return null
  
  const canvasWidth = canvas.clientWidth
  const canvasHeight = canvas.clientHeight
  
  // è½¬æ¢å±å¹•åæ ‡
  const screenX = x * canvasWidth
  const screenY = y * canvasHeight
  
  // ä½¿ç”¨Live2Dçš„hitTestæ–¹æ³•æ£€æµ‹å‘½ä¸­çš„åŒºåŸŸ
  const hitAreaName = live2dManager.hitTestAtScreenCoordinate(screenX, screenY)
  
  if (!hitAreaName) {
    console.log(`ç‚¹å‡»åæ ‡: (${x.toFixed(3)}, ${y.toFixed(3)}), æœªå‘½ä¸­ä»»ä½•HitArea`)
    return null
  }
  
  console.log(`ç‚¹å‡»åæ ‡: (${x.toFixed(3)}, ${y.toFixed(3)}), å‘½ä¸­HitArea: ${hitAreaName}`)
  
  // æŸ¥æ‰¾ä¸å‘½ä¸­åŒºåŸŸå…³è”çš„åŠ¨ä½œå’Œè¡¨æƒ…
  const matchedMotions = []
  const matchedExpressions = []
  
  for (const motion of props.motions) {
    if (motion.clickAreas && motion.clickAreas.includes(hitAreaName)) {
      matchedMotions.push(motion)
    }
  }
  
  for (const expression of props.expressions) {
    if (expression.clickAreas && expression.clickAreas.includes(hitAreaName)) {
      matchedExpressions.push(expression)
    }
  }
  
  console.log(`åŒ¹é…åˆ° ${matchedMotions.length} ä¸ªåŠ¨ä½œ:`, matchedMotions.map(m => m.name))
  console.log(`åŒ¹é…åˆ° ${matchedExpressions.length} ä¸ªè¡¨æƒ…:`, matchedExpressions.map(e => e.name))
  
  // ä¼˜å…ˆå¤„ç†è¡¨æƒ…ï¼Œå¦‚æœæœ‰åŒ¹é…çš„è¡¨æƒ…ä¸”èƒ½æˆåŠŸæ‰§è¡Œå°±è¿”å›
  if (matchedExpressions.length > 0) {
    const randomIndex = Math.floor(Math.random() * matchedExpressions.length)
    const selectedExpression = matchedExpressions[randomIndex]
    console.log(`éšæœºé€‰æ‹©è¡¨æƒ…: ${selectedExpression.name} (ç´¢å¼•: ${randomIndex}/${matchedExpressions.length - 1})`)
    
    // æ‰§è¡Œè¡¨æƒ… - æ”¯æŒfileNameå’ŒfilePathä¸¤ç§æ–¹å¼
    if (live2dManager) {
      if (selectedExpression.filePath) {
        // å¦‚æœæœ‰filePathï¼Œä½¿ç”¨æ–‡ä»¶è·¯å¾„æ‰§è¡Œè¡¨æƒ…
        live2dManager.setExpressionFromFile(selectedExpression.filePath)
        console.log(`é€šè¿‡æ–‡ä»¶è·¯å¾„æ‰§è¡Œè¡¨æƒ…: ${selectedExpression.filePath}`)
        return { type: 'expression', item: selectedExpression }
      } else if (selectedExpression.fileName) {
        // å¦‚æœåªæœ‰fileNameï¼Œä½¿ç”¨æ–‡ä»¶åæ‰§è¡Œè¡¨æƒ…
        live2dManager.startExpression(selectedExpression.fileName)
        console.log(`é€šè¿‡æ–‡ä»¶åæ‰§è¡Œè¡¨æƒ…: ${selectedExpression.fileName}`)
        return { type: 'expression', item: selectedExpression }
      } else {
        console.log(`è¡¨æƒ… ${selectedExpression.name} æ²¡æœ‰å…³è”æ–‡ä»¶ï¼Œæ— æ³•æ‰§è¡Œ`)
        // è¡¨æƒ…æ‰§è¡Œå¤±è´¥ï¼Œç»§ç»­å°è¯•åŠ¨ä½œ
      }
    }
  }
  
  // å¦‚æœæ²¡æœ‰åŒ¹é…çš„è¡¨æƒ…ï¼Œå†å¤„ç†åŠ¨ä½œ
  if (matchedMotions.length > 0) {
    const randomIndex = Math.floor(Math.random() * matchedMotions.length)
    const selectedMotion = matchedMotions[randomIndex]
    console.log(`éšæœºé€‰æ‹©åŠ¨ä½œ: ${selectedMotion.name} (ç´¢å¼•: ${randomIndex}/${matchedMotions.length - 1})`)
    
    // æ‰§è¡ŒåŠ¨ä½œ - ä½¿ç”¨ä¸åŠ¨ä½œé€‰é¡¹ç›¸åŒçš„é€»è¾‘
    if (live2dManager) {
      if (selectedMotion.filePath) {
        // å¦‚æœæœ‰å…³è”çš„æ–‡ä»¶ï¼Œä½¿ç”¨è‡ªå®šä¹‰åŠ¨ä½œæ–‡ä»¶
        live2dManager.setMotionFromFile(selectedMotion.filePath)
        console.log(`é€šè¿‡æ–‡ä»¶è·¯å¾„æ‰§è¡ŒåŠ¨ä½œ: ${selectedMotion.name} (ä½¿ç”¨æ–‡ä»¶: ${selectedMotion.fileName})`)
      } else {
        // ä½¿ç”¨é»˜è®¤åŠ¨ä½œ
        live2dManager.startMotion(selectedMotion.group, selectedMotion.index, 2)
        console.log(`é€šè¿‡ç»„å’Œç´¢å¼•æ‰§è¡ŒåŠ¨ä½œ: ${selectedMotion.group}[${selectedMotion.index}] (é»˜è®¤)`)
      }
    }
    
    return { type: 'motion', item: selectedMotion }
  }
  
  // å¦‚æœæ²¡æœ‰æ‰¾åˆ°å…³è”çš„åŠ¨ä½œï¼Œè§¦å‘area-clickedäº‹ä»¶è®©çˆ¶ç»„ä»¶å¤„ç†
  emit('area-clicked', hitAreaName)
  
  return null
}

// æ¨¡å‹çš„çœŸå®HitAreasä¿¡æ¯
const modelHitAreas = ref([])

// æ£€æŸ¥ç‚¹å‡»æ˜¯å¦å‘½ä¸­æ¨¡å‹çš„HitArea
const isPointInClickArea = (x, y, areaId) => {
  if (!live2dManager || !live2dManager.isModelLoaded) {
    return false
  }
  
  // è·å–canvasçš„æ˜¾ç¤ºå°ºå¯¸
  const canvas = live2dCanvas.value
  if (!canvas) return false
  
  const canvasWidth = canvas.clientWidth
  const canvasHeight = canvas.clientHeight
  
  // è½¬æ¢å±å¹•åæ ‡åˆ°æ ‡å‡†åŒ–åæ ‡
  const screenX = x * canvasWidth
  const screenY = y * canvasHeight
  
  // ä½¿ç”¨Live2Dçš„hitTestæ–¹æ³•æ£€æµ‹
  const hitArea = live2dManager.hitTestAtScreenCoordinate(screenX, screenY)
  
  // æ£€æŸ¥å‘½ä¸­çš„åŒºåŸŸæ˜¯å¦åŒ¹é…æŒ‡å®šçš„areaId
  return hitArea === areaId
}

// è·å–æ¨¡å‹HitAreasä¿¡æ¯
const updateModelHitAreas = () => {
  if (live2dManager && live2dManager.isModelLoaded) {
    modelHitAreas.value = live2dManager.getModelHitAreas()
    console.log('Model HitAreas:', modelHitAreas.value)
  }
}

const randomMotion = () => {
  if (!live2dManager || !live2dManager.isModelLoaded) {
    console.warn('Model not loaded yet')
    return
  }
  
  // å°è¯•æ’­æ”¾ Idle ç»„çš„éšæœºåŠ¨ä½œ
  live2dManager.startMotion('Idle', 0, 2)
}

// Cleanup
const cleanup = () => {
  if (live2dManager) {
    live2dManager.dispose()
    live2dManager = null
  }
  // Stop audio and disconnect nodes
  if (audioSource.value) {
    audioSource.value.disconnect()
  }
  if (analyserNode.value) {
    analyserNode.value.disconnect()
  }
  if (audioContext.value && audioContext.value.state !== 'closed') {
    audioContext.value.close()
  }
  cancelAnimationFrame(animationFrameId)
}

// Watch for model path changes
watch(() => props.modelPath, (newPath) => {
  if (newPath && live2dManager) {
    initLive2D()
  }
})

// Handle window resize
const handleResize = () => {
  if (live2dManager && live2dContainer.value && live2dCanvas.value) {
    const containerRect = live2dContainer.value.getBoundingClientRect()
    const devicePixelRatio = window.devicePixelRatio || 1
    const displayWidth = containerRect.width
    const displayHeight = containerRect.height
    
    // Update canvas size
    live2dCanvas.value.width = displayWidth * devicePixelRatio
    live2dCanvas.value.height = displayHeight * devicePixelRatio
    
    // Update WebGL viewport
    if (live2dManager.gl) {
      live2dManager.gl.viewport(0, 0, live2dCanvas.value.width, live2dCanvas.value.height)
      live2dManager.updateViewMatrix()
    }
  }
}

// Lifecycle hooks
onMounted(() => {
  initLive2D()
  window.addEventListener('resize', handleResize)
})

onUnmounted(() => {
  cleanup()
  window.removeEventListener('resize', handleResize)
})

// --- Audio & Lip Sync Functions ---

/**
 * åˆå§‹åŒ–Web Audio API AudioContext
 * å¿…é¡»åœ¨ç”¨æˆ·äº¤äº’åè°ƒç”¨ä»¥ç¬¦åˆæµè§ˆå™¨è‡ªåŠ¨æ’­æ”¾ç­–ç•¥
 */
const initAudioContext = async () => {
  if (audioContext.value && audioContext.value.state !== 'closed') {
    // AudioContextå·²å­˜åœ¨ä¸”æœªå…³é—­
    if (audioContext.value.state === 'suspended') {
      try {
        await audioContext.value.resume();
        console.log('AudioContext resumed successfully.');
      } catch (e) {
        console.error('Failed to resume AudioContext:', e);
        return false;
      }
    }
    audioContextReady.value = true;
    return true;
  }

  try {
    audioContext.value = new (window.AudioContext || window.webkitAudioContext)();
    analyserNode.value = audioContext.value.createAnalyser();
    analyserNode.value.fftSize = 256;
    
    // æ£€æŸ¥AudioContextçŠ¶æ€
    if (audioContext.value.state === 'suspended') {
      // å¦‚æœè¢«æŒ‚èµ·ï¼Œå°è¯•æ¢å¤ï¼ˆéœ€è¦ç”¨æˆ·äº¤äº’ï¼‰
      try {
        await audioContext.value.resume();
        console.log('AudioContext initialized and resumed successfully.');
      } catch (e) {
        console.warn('AudioContext suspended, waiting for user interaction:', e);
        audioContextReady.value = false;
        return false;
      }
    }
    
    audioContextReady.value = true;
    console.log('AudioContext initialized successfully.');
    return true;
    
  } catch (e) {
    console.error('Failed to initialize AudioContext:', e);
    error.value = 'æ— æ³•åˆå§‹åŒ–éŸ³é¢‘ï¼Œè¯­éŸ³åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚è¯·æ£€æŸ¥æµè§ˆå™¨éŸ³é¢‘æƒé™ã€‚';
    audioContextReady.value = false;
    return false;
  }
};

/**
 * ç¡®ä¿AudioContextå‡†å¤‡å°±ç»ª
 * å¦‚æœéœ€è¦ç”¨æˆ·äº¤äº’ï¼Œä¼šç­‰å¾…ä¸‹ä¸€æ¬¡äº¤äº’
 */
const ensureAudioContextReady = async () => {
  if (audioContextReady.value) {
    return true;
  }
  
  if (!userInteracted.value) {
    console.warn('Audio playback requires user interaction. Please click or tap first.');
    return false;
  }
  
  return await initAudioContext();
};

/**
 * æ’­æ”¾éŸ³é¢‘å¹¶å¯åŠ¨å£å‹åŒæ­¥
 * @param {string} text - è¦è½¬æ¢ä¸ºè¯­éŸ³çš„æ–‡æœ¬
 * @param {string} audioUrl - å¯é€‰çš„éŸ³é¢‘URLï¼Œå¦‚æœæä¾›åˆ™ç›´æ¥æ’­æ”¾
 */
const playAudioWithLipSync = async (text, audioUrl = null) => {
  // ç¡®ä¿AudioContextå‡†å¤‡å°±ç»ª
  const ready = await ensureAudioContextReady();
  if (!ready) {
    console.warn('AudioContext not ready. Audio playback requires user interaction.');
    processingError.value = 'éŸ³é¢‘æ’­æ”¾éœ€è¦ç”¨æˆ·äº¤äº’ï¼Œè¯·å…ˆç‚¹å‡»Live2Dæ¨¡å‹æˆ–é¡µé¢å…¶ä»–ä½ç½®ã€‚';
    return;
  }
  
  if (isPlayingAudio.value) {
    console.log('Already playing audio, stopping previous playback.');
    stopAudioAndLipSync();
  }

  try {
    let audioData;
    
    // 1. è·å–éŸ³é¢‘æ•°æ®
    if (audioUrl) {
      // ä½¿ç”¨æä¾›çš„éŸ³é¢‘URL
      console.log('Playing audio from URL:', audioUrl);
      const response = await fetch(audioUrl);
      if (!response.ok) {
        throw new Error(`Failed to fetch audio: ${response.status}`);
      }
      audioData = await response.arrayBuffer();
    } else {
      // ä»…ä¿ç•™åŒ WS æ¨¡å¼ï¼šä¸å†é€šè¿‡ HTTP æ‹‰å– TTSã€‚
      // è‹¥æœªæä¾› audioUrlï¼ˆåº”æ¥è‡ª WS é‡ç»„ï¼‰ï¼Œåˆ™æç¤ºç”¨æˆ·æˆ–ä¸Šå±‚é€»è¾‘ç¡®ä¿æä¾›ã€‚
      throw new Error('æœªæä¾›å¯æ’­æ”¾çš„éŸ³é¢‘URLï¼ˆå½“å‰ä»…æ”¯æŒé€šè¿‡ WebSocket è·å–çš„éŸ³é¢‘ï¼‰ã€‚');
    }

    // 2. è§£ç éŸ³é¢‘æ•°æ®
    audioBuffer.value = await audioContext.value.decodeAudioData(audioData);

    // 3. è®¾ç½®éŸ³é¢‘æºèŠ‚ç‚¹
    audioSource.value = audioContext.value.createBufferSource();
    audioSource.value.buffer = audioBuffer.value;
    audioSource.value.connect(analyserNode.value);
    analyserNode.value.connect(audioContext.value.destination);

    // 4. å¤„ç†æ’­æ”¾ç»“æŸäº‹ä»¶
    audioSource.value.onended = () => {
      isPlayingAudio.value = false;
      if (live2dManager) {
        live2dManager.setLipSyncValue(0.0); // é‡ç½®å˜´å·´åˆ°å…³é—­çŠ¶æ€
      }
      cancelAnimationFrame(animationFrameId);
      console.log('Audio playback finished.');
    };

    // 5. å¼€å§‹æ’­æ”¾å’Œå£å‹åŒæ­¥
    audioSource.value.start(0);
    isPlayingAudio.value = true;
    startLipSyncLoop();
    console.log('Started audio playback and lip sync.');

  } catch (err) {
    console.error('Error during audio playback:', err);
    processingError.value = `éŸ³é¢‘æ’­æ”¾å¤±è´¥: ${err.message}`;
    isPlayingAudio.value = false;
  }
};

/**
 * åœæ­¢éŸ³é¢‘æ’­æ”¾å’Œå£å‹åŒæ­¥
 */
const stopAudioAndLipSync = () => {
  if (audioSource.value && isPlayingAudio.value) {
    audioSource.value.stop();
    console.log("Audio playback stopped by user.");
  }
  
  // æ˜¾å¼å–æ¶ˆåŠ¨ç”»å¸§
  cancelAnimationFrame(animationFrameId);
  isPlayingAudio.value = false;
  
  if (live2dManager) {
    live2dManager.setLipSyncValue(0.0);
  }
};

/**
 * Fetches audio for the given text, plays it, and syncs lip movement.
 * @param {string} text - The text to be spoken.
 * @deprecated ä½¿ç”¨ playAudioWithLipSync ä»£æ›¿
 */
const speak = async (text) => {
  console.warn('speak() method is deprecated. Use playAudioWithLipSync() instead.');
  return playAudioWithLipSync(text);
};

/**
 * Stops the current audio playback and lip sync animation.
 * @deprecated ä½¿ç”¨ stopAudioAndLipSync ä»£æ›¿
 */
const stopSpeaking = () => {
  console.warn('stopSpeaking() method is deprecated. Use stopAudioAndLipSync() instead.');
  return stopAudioAndLipSync();
};


// Expose methods for parent component
defineExpose({
  // Method to get the manager instance
  getManager: () => live2dManager,
  
  // Audio methods (new unified API)
  initAudioContext,
  playAudioWithLipSync,
  stopAudioAndLipSync,
  ensureAudioContextReady,
  
  // Audio methods (deprecated but kept for compatibility)
  speak,
  stopSpeaking,
  
  // Audio status getters
  getAudioContextReady: () => audioContextReady.value,
  getUserInteracted: () => userInteracted.value,
  getIsPlayingAudio: () => isPlayingAudio.value,
  
  // Test methods
  testLipSyncAnimation,
  testRandomMotion,

  // Existing exposed methods
  playMotion: (motionGroup, motionIndex = 0) => {
    if (live2dManager) {
      live2dManager.playMotion(motionGroup, motionIndex)
    }
  },
  setExpression: (expressionId) => {
    if (live2dManager) {
      live2dManager.setExpression(expressionId)
    }
  },
  setExpressionFromFile: async (fileUrl) => {
    if (live2dManager) {
      try {
        await live2dManager.setExpressionFromFile(fileUrl)
      } catch (error) {
        console.error('Failed to set expression from file:', error)
        throw error
      }
    }
  },
  setMotionFromFile: async (fileUrl) => {
    if (live2dManager) {
      try {
        await live2dManager.setMotionFromFile(fileUrl)
      } catch (error) {
        console.error('Failed to set motion from file:', error)
        throw error
      }
    }
  }
})

// --- Helper Functions ---

/**
 * å¼€å§‹å£å‹åŒæ­¥çš„åŠ¨ç”»å¾ªç¯
 */
const startLipSyncLoop = () => {
  if (!analyserNode.value || !live2dManager) return;

  const bufferLength = analyserNode.value.frequencyBinCount;
  const dataArray = new Uint8Array(bufferLength);

  const updateLipSync = () => {
    analyserNode.value.getByteFrequencyData(dataArray);

    // è®¡ç®—éŸ³é‡ - ä¸€ä¸ªç®€å•çš„å®ç°
    let sum = 0;
    for (let i = 0; i < bufferLength; i++) {
      sum += dataArray[i];
    }
    const average = sum / bufferLength;

    // å°†éŸ³é‡æ˜ å°„åˆ°å˜´éƒ¨å¼€åˆå‚æ•° (0.0 - 1.0)
    // è¿™ä¸ªæ˜ å°„å…³ç³»å¯èƒ½éœ€è¦æ ¹æ®ä½ çš„æ¨¡å‹å’ŒéŸ³é¢‘è¿›è¡Œå¾®è°ƒ
    const volume = Math.min(Math.max(average / 100, 0), 1.0);
    
    // å°†å€¼ä¼ é€’ç»™Live2Dæ¨¡å‹
    live2dManager.setLipSyncValue(volume);

    // å¦‚æœè¿˜åœ¨æ’­æ”¾ï¼Œç»§ç»­ä¸‹ä¸€å¸§
    if (isPlayingAudio.value) {
      animationFrameId = requestAnimationFrame(updateLipSync);
    }
  };

  // å¯åŠ¨å¾ªç¯
  animationFrameId = requestAnimationFrame(updateLipSync);
};
</script>

<style scoped>
.live2d-container {
  position: relative;
  width: 100%;
  height: 100%;
  display: flex;
  justify-content: center;
  align-items: center;
  /* ç§»é™¤èƒŒæ™¯æ¸å˜ï¼Œè®©Live2Dçš„WebGLèƒŒæ™¯å æ»¡æ•´ä¸ªåŒºåŸŸ */
  background: transparent;
  border-radius: 12px;
  overflow: hidden;
}

.live2d-canvas {
  display: block;
  /* è®©canvaså æ»¡æ•´ä¸ªå®¹å™¨ */
  width: 100%;
  height: 100%;
  border-radius: 12px;
  box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
  /* ç¡®ä¿canvasä¸ä¼šè¢«CSSæ‹‰ä¼¸å˜å½¢ */
  object-fit: cover;
  /* å¯ç”¨ç¡¬ä»¶åŠ é€Ÿ */
  transform: translateZ(0);
  /* ä¼˜åŒ–æ¸²æŸ“è´¨é‡ */
  image-rendering: -webkit-optimize-contrast;
  image-rendering: crisp-edges;
}

.loading-overlay,
.error-overlay {
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
  background: rgba(255, 255, 255, 0.9);
  backdrop-filter: blur(4px);
  border-radius: 12px;
}

.loading-overlay p,
.error-overlay p {
  margin: 0;
  font-size: 14px;
  color: #666;
}

.error-overlay p {
  color: #d32f2f;
}
</style>
