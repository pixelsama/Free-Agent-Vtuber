# Live2D聊天桃汐 - 后端接口文档

## 项目概述

这是一个基于Vue.js + Vuetify的Live2D聊天应用前端，集成了实时语音转文本、智能对话和Live2D角色展示功能。本文档为后端开发者提供完整的API接口规范。

## 技术栈

- **前端框架**: Vue 3 + Vuetify 3
- **通信协议**: WebSocket (双向实时通信)
- **数据格式**: JSON + 二进制数据块
- **音频处理**: MediaRecorder API (WebM/Opus格式)

## 核心架构

前端采用双WebSocket连接模式：
1. **输入连接** (`/ws/input`): 用于上传用户输入数据（文本/音频）
2. **输出连接** (`/ws/output/{task_id}`): 用于接收AI处理结果

## WebSocket接口规范

### 1. 输入WebSocket接口

**端点**: `ws://域名:8000/ws/input`

#### 连接流程

1. **建立连接**
   - 客户端连接到 `/ws/input`
   - 服务器返回任务ID分配消息

2. **任务ID分配消息**
```json
{
  "type": "system",
  "action": "task_id_assigned",
  "task_id": "uuid-string"
}
```

3. **数据上传流程**
   - 发送元数据JSON
   - 发送二进制数据块
   - 发送上传完成信号

4. **上传处理确认**
```json
{
  "type": "system",
  "action": "upload_processed",
  "status": "queued",
  "task_id": "uuid-string"
}
```

#### 文本输入格式

**元数据消息**:
```json
{
  "type": "text",
  "chunk_id": 0,
  "action": "data_chunk"
}
```

**二进制数据**: UTF-8编码的文本字节

**上传完成信号**:
```json
{
  "action": "upload_complete"
}
```

#### 音频输入格式

**注意**: 前端使用 `MediaRecorder` API (`audio/webm;codecs=opus`) 进行录制，并将 `ondataavailable` 事件产生的 `Blob` 块直接发送。后端需要能够处理这种不定大小的流式块。

**元数据消息**:
```json
{
  "type": "audio",
  "chunk_id": 0,
  "action": "data_chunk"
}
```

**二进制数据**: `MediaRecorder` 生成的 `audio/webm` 格式的 `Blob` 块。

**上传完成信号**:
```json
{
  "action": "upload_complete"
}
```

#### 错误处理

**块ID不匹配错误**:
```
"Chunk ID mismatch: expected X, got Y"
```

**确认消息**:
```
"File chunk received"
```

### 2. 输出WebSocket接口

**端点**: `ws://域名:8000/ws/output/{task_id}`

#### 连接要求
- 必须在输入连接获得task_id后才能连接
- task_id必须是有效的UUID字符串

#### 响应消息格式与流程

当响应包含音频时，数据传输遵循严格的顺序。

**1. 成功响应（包含音频）**
首先，服务器发送一个JSON消息，通知客户端AI文本内容，并告知即将开始音频传输。
```json
{
  "status": "success",
  "task_id": "uuid-string",
  "content": "AI回复的文本内容",
  "audio_present": true
}
```

**2. 音频传输流程 (循环进行)**
对于每一个音频块，服务器必须 **先发送元数据，紧接着发送二进制数据**。

   **a. 音频块元数据 (JSON)**
   此消息描述了紧随其后的二进制块。
   ```json
   {
     "type": "audio_chunk",
     "task_id": "uuid-string",
     "chunk_id": 0,         // 当前块的索引 (从0开始)
     "total_chunks": 5      // 音频总块数
   }
   ```
   - `chunk_id: 0` 的元数据标志着音频传输的开始。客户端会根据 `total_chunks` 初始化一个相应大小的数组来准备接收。

   **b. 音频块 (二进制)**
   紧跟在元数据JSON消息之后，发送原始的二进制音频数据块。

**3. 音频完成信号**
所有块都发送完毕后，服务器发送一个完成信号。
```json
{
  "type": "audio_complete",
  "task_id": "uuid-string"
}
```
客户端在收到此信号后，会开始重组音频并断开连接。

**4. 成功响应（仅文本）**
如果响应不包含音频，流程非常简单。
```json
{
  "status": "success",
  "task_id": "uuid-string",
  "content": "AI回复的文本内容",
  "audio_present": false
}
```

**错误响应**:
```json
{
  "status": "error",
  "error": "错误描述信息"
}
```

## 数据传输规范

### 音频数据处理

#### 输入音频
- **格式**: `audio/webm;codecs=opus`。
- **获取方式**: 前端使用 `MediaRecorder` API。
- **传输**: 直接发送 `MediaRecorder` `ondataavailable` 事件生成的 `Blob` 块。每个块前附带一个JSON元数据消息。后端需要能处理大小不定的流式块。

#### 输出音频
- **格式**: 最终可播放的 `audio/mpeg`（MP3）格式。
- **传输**: 后端将完整的 MP3 文件分块发送。所有二进制块按顺序拼接后必须能构成一个有效的 MP3 文件（通常首块包含必要的文件头信息）。
- **重组**: 客户端会严格按照 `chunk_id` 的顺序将接收到的二进制块存入数组。收到 `audio_complete` 信号后，将所有块合并（`new Blob(chunks, { type: 'audio/mpeg' })`）并生成可播放的 URL。
- **错误处理**: 如果客户端收到的块数量与 `total_chunks` 不匹配，或在接收过程中连接中断，该次音频接收将被视为失败并丢弃数据。

### 文本数据处理

#### 输入文本
- **编码**: UTF-8
- **传输**: JSON元数据 + 编码后的二进制数据

#### 输出文本
- **格式**: JSON字符串
- **编码**: UTF-8

## 错误处理规范

### 连接错误
- WebSocket连接失败
- 网络超时
- 服务器不可用

### 数据传输错误
- 块ID不匹配
- 数据格式错误
- 文件过大

### 业务逻辑错误
- 任务ID无效
- 处理超时
- AI服务异常

## 状态管理

### 前端状态追踪

```javascript
{
  taskId: null,                    // 当前任务ID
  isConnectedInput: false,         // 输入连接状态
  isConnectedOutput: false,        // 输出连接状态
  isProcessing: false,             // 处理状态
  uploadCompleteConfirmed: false,  // 上传确认状态
  processingError: null,           // 错误信息
  receivedText: '',               // 接收的文本
  receivedAudioUrl: null,         // 音频URL
  isRecording: false,             // 录音状态
  recordingError: null            // 录音错误
}
```

## 实现建议

### 后端WebSocket处理器

1. **输入处理器** (`/ws/input`)
   - 生成唯一task_id
   - 接收并缓存数据块
   - 验证数据完整性
   - 队列化处理任务

2. **输出处理器** (`/ws/output/{task_id}`)
   - 验证task_id有效性
   - 推送处理结果
   - 支持音频分块传输

### 数据存储

```
临时存储结构:
/tmp/tasks/{task_id}/
  ├── input.txt     # 文本输入
  ├── input.wav     # 音频输入
  ├── output.txt    # 文本输出
  └── output.wav    # 音频输出
```

### 处理流程（仅双 WebSocket）

```
1. 客户端连接输入WS → 分配 task_id
2. 客户端上传数据（文本/音频）→ 后台入队处理
3. 输入端收到“upload_processed/queued”后可断开
4. 客户端连接输出WS（带 task_id）→ 验证 task_id
5. 后台处理完成 → 先发送文本 JSON → 若有音频则循环发送“音频块元数据 JSON → 紧随二进制块”
6. 发送 audio_complete → 客户端重组 MP3（Blob type: audio/mpeg）→ 播放
7. 传输完成 → 清理临时文件
```

## 配置参数

### 服务器配置
```yaml
websocket:
  input_endpoint: "/ws/input"
  output_endpoint: "/ws/output"
  max_connections: 1000
  timeout: 300  # 秒

upload:
  max_file_size: 50MB
  chunk_size: 64KB
  supported_formats: ["text/plain", "audio/webm"]

audio:
  output_format: "mp3"
  sample_rate: 44100
  channels: 1
```

### 客户端配置
```javascript
// 仅保留双 WebSocket 模式（不再使用 HTTP 拉取 TTS）
const wsProtocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
const wsBaseUrl = `${wsProtocol}//${window.location.hostname}:8000`;
const wsInputUrl = `${wsBaseUrl}/ws/input`;
// 输出连接在获得 task_id 后：`${wsBaseUrl}/ws/output/${taskId}`
```

## 测试用例

### 文本输入测试
```javascript
// 1. 连接输入WS
// 2. 等待task_id
// 3. 发送文本元数据
// 4. 发送文本数据
// 5. 发送上传完成
// 6. 连接输出WS
// 7. 接收响应
```

### 音频输入测试
```javascript
// 1. 录制音频
// 2. 连接输入WS
// 3. 分块上传音频
// 4. 连接输出WS
// 5. 接收文本和音频响应
```

## 安全考虑

### 数据验证
- 验证文件格式和大小
- 检查块ID连续性
- 限制上传频率

### 连接管理
- 限制并发连接数
- 实现连接超时
- 清理僵尸连接

### 错误处理
- 敏感信息脱敏
- 详细日志记录
- 优雅降级机制

## 性能优化

### 内存管理
- 大文件流式处理
- 及时清理临时文件
- 限制并发处理数

### 网络优化
- 数据压缩
- 连接复用
- 断线重连机制

---

## 联系信息

如有技术问题，请联系前端团队获取更多详细信息。

**文档版本**: 1.0  
**最后更新**: 2025-01-11
